{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20X Dataset\n",
    "Downsample the 40X ROIs from the NFT detection project to 20X. Then tile the new ROIs into a dataset.\n",
    "\n",
    "This notebook is final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from pandas import read_csv, concat, DataFrame\n",
    "from os.path import join, isfile\n",
    "from shutil import copyfile, rmtree\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "\n",
    "from neurotk import imread, imwrite\n",
    "from neurotk.utils import create_dirs, get_filename, im_to_txt_path\n",
    "from neurotk import tile_roi_with_labels_wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save figures even if they already exist, then set this \n",
    "# parameter to True.\n",
    "OVERWRITE = False\n",
    "\n",
    "# Location to save 20X dataset.\n",
    "SAVE_DIR = '/jcDataStore/Data/NeuroTK-Dash/nft-detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample 40X ROIs to 20X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample ROIs to 20X.\n",
    "roi_csv_fp = join(SAVE_DIR, 'rois.csv')\n",
    "\n",
    "if OVERWRITE or not isfile(roi_csv_fp):\n",
    "    # Get info for ROIs used for training and validation datasets. \n",
    "    src_rois_df = concat(\n",
    "        [\n",
    "            read_csv('/jcDataStore/Data/nft-ai-project/datasets/'\n",
    "                    'model-assisted-labeling/rois.csv'),\n",
    "            read_csv('/jcDataStore/Data/nft-ai-project/datasets/'\n",
    "                    'model-assisted-labeling/background-rois.csv')\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Replace filepaths to be relative to local filepaths.\n",
    "    src_rois_df = src_rois_df.replace(\n",
    "        '/workspace/data/jcDataStore/Data/nft-ai-project/', regex=True\n",
    "    )\n",
    "\n",
    "    # Saving new dataframe with upated paths and magnification.\n",
    "    rois_df = []\n",
    "    \n",
    "    roi_img_dir = join(SAVE_DIR, 'rois/images')\n",
    "    roi_label_dir = join(SAVE_DIR, 'rois/labels')\n",
    "    roi_bound_dir = join(SAVE_DIR, 'rois/boundaries')\n",
    "\n",
    "    rmtree(roi_img_dir)\n",
    "    rmtree(roi_label_dir)\n",
    "    rmtree(roi_bound_dir)\n",
    "    create_dirs([roi_img_dir, roi_label_dir, roi_bound_dir])\n",
    "\n",
    "    # Loop through each ROI.\n",
    "    for _, r in tqdm(src_rois_df.iterrows(), total=len(src_rois_df)):\n",
    "        fn = get_filename(r.fp)\n",
    "        \n",
    "        new_img_fp = join(roi_img_dir, fn + '.png')\n",
    "        \n",
    "        # Read the image.\n",
    "        img = imread(r.fp)\n",
    "        \n",
    "        # Resize image.        \n",
    "        img = cv.resize(img, None, fx=0.5, fy=0.5, interpolation=cv.INTER_AREA)\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        imwrite(new_img_fp, img)\n",
    "            \n",
    "        # Save the corresponding label and boundary file.\n",
    "        label_fp = im_to_txt_path(r.fp)\n",
    "        bound_fp = im_to_txt_path(r.fp, txt_dir='boundaries')\n",
    "                \n",
    "        if isfile(label_fp):\n",
    "            copyfile(label_fp, join(roi_label_dir, fn + '.txt'))\n",
    "            \n",
    "        if isfile(bound_fp):\n",
    "            copyfile(bound_fp, join(roi_bound_dir, fn + '.txt'))\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                f'Missing ROI boundary file for \\\"{r.fp}\\\".'\n",
    "            )\n",
    "                \n",
    "        # Track the ROI metadata.\n",
    "        r = r.copy()\n",
    "        r.mag = 20\n",
    "        r.fp = new_img_fp\n",
    "        r.h = h\n",
    "        r.w = w\n",
    "        r.sf = 0.5\n",
    "        rois_df.append(r)\n",
    "        \n",
    "    rois_df = DataFrame(rois_df)\n",
    "    rois_df.to_csv(roi_csv_fp, index=False)\n",
    "else:\n",
    "    rois_df = read_csv(roi_csv_fp)\n",
    "    \n",
    "rois_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multi-parallel processing when doing this.\n",
    "tiles_csv_fp = join(SAVE_DIR, 'tiles.csv')\n",
    "\n",
    "if OVERWRITE or not isfile(tiles_csv_fp):\n",
    "    # Note: most recent version of shapely throws warnings when there is no \n",
    "    # intersection between two geometris. This is not an issue but the warnings \n",
    "    # are annoying. May put a catch later to avoid this.\n",
    "    tiles_df = tile_roi_with_labels_wrapper(\n",
    "        rois_df.fp.tolist(), \n",
    "        join(SAVE_DIR, 'tiles'), \n",
    "        tile_size=1280,\n",
    "        stride=960,\n",
    "        boundary_thr=0.2,\n",
    "        nproc=10,\n",
    "        box_thr=0.5,\n",
    "        notebook=True\n",
    "    )\n",
    "    \n",
    "    tiles_df.to_csv(tiles_csv_fp, index=False)\n",
    "else:\n",
    "    tiles_df = read_csv(tiles_csv_fp)\n",
    "    \n",
    "tiles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and validation by WSI images belong to. To do this add\n",
    "# the WSI to each tile image.\n",
    "roi_to_wsi_map = {r.fp: r.wsi_name for _, r in rois_df.iterrows()}\n",
    "\n",
    "tiles_df['wsi_name'] = [''] * len(tiles_df)\n",
    "\n",
    "for i, r in tiles_df.iterrows():\n",
    "    tiles_df.loc[i, 'wsi_name'] = roi_to_wsi_map[r.roi_fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the tiles into train and val at 90:10 split.\n",
    "train_wsis, val_wsis = train_test_split(\n",
    "    sorted(list(tiles_df.wsi_name.unique())),\n",
    "    train_size=0.9,\n",
    "    random_state=64\n",
    ")\n",
    "\n",
    "train_tiles = tiles_df[tiles_df.wsi_name.isin(train_wsis)]\n",
    "val_tiles = tiles_df[tiles_df.wsi_name.isin(val_wsis)]\n",
    "\n",
    "# Create train.txt, val.txt and the dataset.yaml file.\n",
    "with open(join(SAVE_DIR, '20X-train.txt'), 'w') as fh:\n",
    "    lines = ''\n",
    "    \n",
    "    for fp in train_tiles.fp:\n",
    "        lines += f'{fp}\\n'\n",
    "        \n",
    "    fh.write(lines.strip())\n",
    "    \n",
    "with open(join(SAVE_DIR, '20X-val.txt'), 'w') as fh:\n",
    "    lines = ''\n",
    "    \n",
    "    for fp in val_tiles.fp:\n",
    "        lines += f'{fp}\\n'\n",
    "        \n",
    "    fh.write(lines.strip())\n",
    "    \n",
    "yaml_dict = {\n",
    "    'names': ['Pre-NFT', 'iNFT'],\n",
    "    'nc': 2,\n",
    "    'path': SAVE_DIR,\n",
    "    'train': '20X-train.txt',\n",
    "    'val': '20X-val.txt'\n",
    "}\n",
    "\n",
    "with open(join(SAVE_DIR, '20X-dataset.yaml'), 'w') as fh:\n",
    "    yaml.dump(yaml_dict, fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissue-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
