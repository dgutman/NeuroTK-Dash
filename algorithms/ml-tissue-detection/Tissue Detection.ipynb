{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0794404e-b233-4551-aed6-9cc0a306c95d",
   "metadata": {},
   "source": [
    "# Tissue Detection\n",
    "Last updated: 08/14/2023\n",
    "\n",
    "Use low resolution WSIs from Emory & UC Davis and their tissue mask (created by HistomicsTK tissue detection function and curated by JC) to train a semantic segmentation model (DeepLabV3) to predict tissue regions in WSIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2ab70-f553-408a-8c75-5a8da6078bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from glob import glob\n",
    "from os.path import isfile\n",
    "from pandas import DataFrame, read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "from neurotk import imread\n",
    "from neurotk.utils import replace_last_occurence\n",
    "from neurotk.torch import EarlyStopping, train_binary_ss_model\n",
    "from neurotk.torch.datasets import BinarySSDataset\n",
    "from neurotk.torch.models import deeplabv3_model\n",
    "from neurotk.torchvision.semantic_segmentation_transforms import (\n",
    "    Normalize, ToTensor, Resize, RandomHorizontalFlip, RandomVerticalFlip,\n",
    "    RandomRotation, ColorJitter, Compose\n",
    ")\n",
    "from neurotk.torchvision.transforms import UnNormalize\n",
    "from neurotk.torch.metrics import binary_dice_coefficient\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b2775-8756-45b5-b42a-1592e417c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV / load DataFrame for the tissue detection dataset*.\n",
    "# * We use the dataset created in the YOLO Braak Stage project for WSI \n",
    "# inference.\n",
    "dataset_csv_fp = '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/' + \\\n",
    "                 'tissue-dataset.csv'  # file path to CSV file\n",
    "\n",
    "if isfile(dataset_csv_fp):\n",
    "    dataset_df = read_csv(dataset_csv_fp)\n",
    "else:\n",
    "    dataset_df = []\n",
    "    \n",
    "    # Loop through all the images.\n",
    "    for img_fp in glob('/jcDataStore/Data/nft-ai-project/wsi-inference/'\n",
    "                       'tissue-masks/images/*.png'):\n",
    "        # Read image.\n",
    "        img = imread(img_fp)           \n",
    "        \n",
    "        # Get path to image label, always located in parallel path, in \"masks\" \n",
    "        # directory.\n",
    "        label_fp = replace_last_occurence(img_fp, '/images/', '/masks/', \n",
    "                                          required=True)\n",
    "    \n",
    "        # Label file must exist.\n",
    "        if not isfile(label_fp):\n",
    "            raise FileExistsError(f'Label file ({label_fp}) does not exist.')\n",
    "    \n",
    "        dataset_df.append([img_fp, label_fp])\n",
    "    \n",
    "    dataset_df = DataFrame(dataset_df, columns=['fp', 'label'])\n",
    "    dataset_df.to_csv(dataset_csv_fp, index=False)\n",
    "\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446a79e-de65-4874-ba3c-ce18cd98eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "val_frac = 0.1  # fraction of images to set as validation\n",
    "random_state = 64  # set to None to keep it random\n",
    "lr = 1e-4  # learning rate, something small like 1e-4\n",
    "device = None  # will default to first GPU or CPU if not available\n",
    "size = 256  # size of image to train with\n",
    "\n",
    "# Color normalization mean and standard deviation to use with LabView.\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84722490-cf66-4ba3-8b77-18843e4ec08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders.\n",
    "train_df, val_df = train_test_split(dataset_df, test_size=val_frac, \n",
    "                                    random_state=random_state)\n",
    "\n",
    "# Data augmentation transforms.\n",
    "transforms = Compose([\n",
    "    ToTensor(), \n",
    "    Resize((size, size)), \n",
    "    RandomHorizontalFlip(), \n",
    "    RandomVerticalFlip(), \n",
    "    RandomRotation(90, fill=1),\n",
    "    ColorJitter(brightness=0.1, contrast=0.005, saturation=0.2, hue=0.02),\n",
    "    Normalize(mean=norm_mean, std=norm_std)\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Resize((size, size)),\n",
    "    Normalize(mean=norm_mean, std=norm_std)\n",
    "])\n",
    "\n",
    "# Create dataloaders, set as dictionary with 'train' and 'val'.\n",
    "dataloaders = {\n",
    "    'train': DataLoader(\n",
    "        BinarySSDataset(train_df, transforms=transforms), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    ),\n",
    "    'val': DataLoader(\n",
    "        BinarySSDataset(val_df, transforms=val_transforms), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False\n",
    "    )\n",
    "}\n",
    "\n",
    "# Visualize a batch from the training dataset.\n",
    "sample = next(iter(dataloaders['train']))\n",
    "img_grid = make_grid(sample['image'], nrow=4)\n",
    "\n",
    "unorm = UnNormalize(mean=norm_mean, std=norm_std)\n",
    "img_grid = unorm(img_grid)\n",
    "\n",
    "F.to_pil_image(img_grid).show()\n",
    "plt.show()\n",
    "\n",
    "mask_grid = make_grid(sample['mask'], nrow=4)\n",
    "F.to_pil_image(mask_grid).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19d771-c019-4933-86e9-38e53b81394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model.\n",
    "model = deeplabv3_model()\n",
    "\n",
    "# Optimizer gets fed in the model parameters and learning rate.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Specify the loss function\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Set up the metrics\n",
    "metrics = {'dice coefficient': binary_dice_coefficient()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e026b2-4c69-49f9-8859-a0201ed97403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_binary_ss_model(\n",
    "    model,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    metrics,\n",
    "    epochs=5,\n",
    "    device=device,\n",
    "    early_stopper=EarlyStopping(),\n",
    "    # save_dir='/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/models/test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93893c3-c53f-423c-9166-d54a27b57d13",
   "metadata": {},
   "source": [
    "## Load model and predict on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abaf84-1004-4873-a73f-74072d555d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a blank model.\n",
    "model = deeplabv3_model()\n",
    "\n",
    "# Load the weights.\n",
    "model.load_state_dict(torch.load(\n",
    "    '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/models/run1/best.pt'    \n",
    "))\n",
    "\n",
    "# Prevent weights from adjusting.\n",
    "model.eval()\n",
    "\n",
    "# Read an image to predict on.\n",
    "img = Image.open('/jcDataStore/Data/nft-ai-project/wsi-inference/tissue-masks/images/A16-66_6_tau.png')\n",
    "orig_shape = img.size\n",
    "img.show()\n",
    "\n",
    "# Read its mask.\n",
    "true = Image.open('/jcDataStore/Data/nft-ai-project/wsi-inference/tissue-masks/masks/A16-66_6_tau.png')\n",
    "true.show()\n",
    "\n",
    "# Apply transform to image before predicting.\n",
    "img, _ = val_transforms(img, true)\n",
    "\n",
    "# Predict the mask\n",
    "with torch.set_grad_enabled(False):\n",
    "    img = img.unsqueeze(0)\n",
    "    pred = model(img)['out']\n",
    "\n",
    "# Visualize the prediction.\n",
    "pred = (pred[0][0] > 0.1).data.cpu().numpy()\n",
    "\n",
    "# Lets reshape to original size.\n",
    "pred = pred.astype(np.uint8) * 255\n",
    "pred = cv.resize(pred, orig_shape, None, None, cv.INTER_NEAREST)\n",
    "Image.fromarray(pred).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissue-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
