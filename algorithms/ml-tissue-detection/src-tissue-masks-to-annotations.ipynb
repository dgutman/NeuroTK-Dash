{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b25539-9e0b-48e7-8c9e-8bc8bef68109",
   "metadata": {},
   "source": [
    "# Source Tissue Masks to Annotations\n",
    "\n",
    "Status: complete\n",
    "\n",
    "The source images are low resolution WSIs with binary masks for the tissue that were generated as part of the NFT detection project (a.k.a. YOLO Braak project). In this notebook we extract contours for those masks and push them as DSA annotations, to its WSI in the Emory-ADRC collection (megabrain server)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dbbdcf3c-4df0-441c-a968-8c5d28adac01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from pandas import read_csv\n",
    "from os.path import join, splitext\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import large_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from neurotk import login, imread\n",
    "from neurotk.girder_utils import get_tile_metadata, get_annotations_documents\n",
    "from neurotk.utils import contours_to_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f8f67a1-a4f6-4dbf-a2de-1348d584582c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Password for jvizcar:  ········\n"
     ]
    }
   ],
   "source": [
    "# Girder client active session.\n",
    "# gc1 = login('https://computablebrain.emory.edu/api/v1', username='jvizcar')\n",
    "gc = login('https://megabrain.neurology.emory.edu/api/v1', username='jvizcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a75df480-208e-454c-b043-62745241a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directories.\n",
    "root_dir = '/jcDataStore/Data/nft-ai-project/wsi-inference'\n",
    "mask_dir = join(root_dir, 'tissue-masks/masks')\n",
    "sf = 40 / 0.25  # scale factor from low res mask to WSI scale\n",
    "doc_name = 'htk-manual-tissue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7ec28b0-8879-43c4-b1f5-f5bd053f3a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 447/447 [03:58<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read the WSI information.\n",
    "wsi_metadata = read_csv(join(root_dir, 'wsis.csv'))\n",
    "\n",
    "# Loop for each WSI.\n",
    "for _, r in tqdm(wsi_metadata.iterrows(), total=len(wsi_metadata)):\n",
    "    # Look for this image in Megabrain.\n",
    "    fp = f\"/collection/Emory-ADRC/{r.filepath.split('/wsis/')[1]}\"\n",
    "    fp = fp.replace('/', '%2F')\n",
    "    item = gc.get(f'resource/lookup?path={fp}')\n",
    "\n",
    "    # Ignore if item of same name / filepath is not in Megabrain.\n",
    "    if item:\n",
    "        # Skip if the annotation document is already there.\n",
    "        exist_flag = False\n",
    "        \n",
    "        for ann_doc in get_annotations_documents(gc, item['_id']):\n",
    "            if ann_doc.get('annotation', {}).get('name') == doc_name:\n",
    "                exist_flag = True\n",
    "                break\n",
    "\n",
    "        if exist_flag:\n",
    "            continue\n",
    "            \n",
    "        # Get the filename without extension.\n",
    "        fn = splitext(r.wsi_name)[0]\n",
    "    \n",
    "        # Read mask file.\n",
    "        mask_fp = join(mask_dir, fn + '.png')\n",
    "        mask = (imread(mask_fp)[:, :, 0] > 0).astype(np.uint8)\n",
    "    \n",
    "        # Extract contours.\n",
    "        contours = cv.findContours(mask, cv.RETR_TREE, \n",
    "                                   cv.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "        smoothed_contours = []\n",
    "\n",
    "        for contour in contours:\n",
    "            smoothed_contours.append(cv.approxPolyDP(contour, 1, True))\n",
    "    \n",
    "        # Convert the list of contours to points in DSA format.\n",
    "        tissue_points = contours_to_points(smoothed_contours)\n",
    "    \n",
    "        # Convert each contour into a list dictionary to pass as an annotation \n",
    "        # DSA element.\n",
    "        tissue_els = []\n",
    "    \n",
    "        for pt in tissue_points:\n",
    "            # Skip a point with too few points*\n",
    "            # * DSA appears to prevent annotations of three points only.\n",
    "            if len(pt) < 4:\n",
    "                continue\n",
    "                \n",
    "            # Scale the points\n",
    "            pt = np.array(pt) * sf\n",
    "            \n",
    "            tissue_els.append({\n",
    "                'group': doc_name,\n",
    "                'type': 'polyline',\n",
    "                'lineColor': 'rgb(0,179,60)',\n",
    "                'lineWidth': 4.0,\n",
    "                'closed': True,\n",
    "                'points': pt.tolist(),\n",
    "                'label': {'value': doc_name},\n",
    "            })\n",
    "\n",
    "        # Push as annotations.\n",
    "        _ = gc.post(\n",
    "            f\"/annotation?itemId={item['_id']}\", \n",
    "            json={\n",
    "                'name': doc_name, \n",
    "                'description': 'Extracted from low res binary masks.', \n",
    "                'elements': tissue_els})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-tissue-detection]",
   "language": "python",
   "name": "conda-env-ml-tissue-detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
