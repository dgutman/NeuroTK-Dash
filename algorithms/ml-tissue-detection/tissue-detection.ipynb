{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3dfa082-3eeb-4ecf-9b3d-48efadb96f8e",
   "metadata": {},
   "source": [
    "# Detection WSI Tissue with Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe2695-d910-4187-9855-bddcef30fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926cb844-085c-4033-9338-1fb16a211b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from neurotk.torch.models import deeplabv3_model\n",
    "from neurotk.torchvision.semantic_segmentation_transforms import (\n",
    "    Normalize, ToTensor, Resize, Compose\n",
    ")\n",
    "from neurotk import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a4723-ceb5-4aac-9ba0-e61d29f8d4ea",
   "metadata": {},
   "source": [
    "## Viewing Predictions from Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07280544-e5ab-4916-ab97-7b40ca1343d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a standard model and load pre-trained weights.\n",
    "state_dict_fp = '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/models/run1/best.pt'\n",
    "model = deeplabv3_model()\n",
    "model.load_state_dict(torch.load(state_dict_fp))\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9b960-9945-4fb4-8b3b-0a567ca37d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a sample image.\n",
    "img_fp = '/jcDataStore/Data/nft-ai-project/wsi-inference/tissue-masks/images/NA5023-02_AT8.png'\n",
    "# img = Image.open('/jcDataStore/Data/nft-ai-project/wsi-inference/tissue-masks/images/1023340.png')\n",
    "mask = Image.open('/jcDataStore/Data/nft-ai-project/wsi-inference/tissue-masks/masks/NA5023-02_AT8.png')\n",
    "\n",
    "\n",
    "def contours_to_points(contours):\n",
    "    \"\"\"Convert a list of opencv contours (i.e. contour shape is \n",
    "    (num_points, 1, 2) with x, y order) to a list of x,y point in format \n",
    "    ready to push as DSA annotations. This form is a list of lists with \n",
    "    [x, y, z] format where the z is always 0.\n",
    "    \n",
    "    Args:\n",
    "        contours: List of numpy arrays in opencv contour format\n",
    "\n",
    "    Returns:\n",
    "        Points in DSA format.\n",
    "    \n",
    "    \"\"\"\n",
    "    points = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        points.append([\n",
    "            [float(pt[0][0]), float(pt[0][1]), 0] for pt in contour\n",
    "        ])\n",
    "        \n",
    "    return points\n",
    "\n",
    "\n",
    "def predict_mask(model, img, size=256, norm=None, thresh=0.7):\n",
    "    \"\"\"Predict mask on the image given the model, and output the mask\n",
    "    in the same aspect ratio as the input image.\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()  # should not be modifying weights\n",
    "    \n",
    "    if isinstance(img, str):\n",
    "        img = Image.open(img)\n",
    "    elif isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "    elif not isinstance(img, Image.Image):\n",
    "        raise TypeError(\n",
    "            'img must be a filepath string, ndarray, or PIL image'\n",
    "        )\n",
    "\n",
    "    if norm is None:\n",
    "        # Default normalization values for ImageNet.\n",
    "        norm = {\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225]\n",
    "        }\n",
    "\n",
    "    # Get the original shape of the image.\n",
    "    orig_shape = img.size\n",
    "\n",
    "    # Apply transforms to image.\n",
    "    transforms = Compose([\n",
    "        ToTensor(),\n",
    "        Resize((size, size)),\n",
    "        Normalize(mean=norm['mean'], std=norm['std'])\n",
    "    ])\n",
    "\n",
    "    img = transforms(img, Image.new('L', orig_shape))[0]\n",
    "\n",
    "    # Predict the mask.\n",
    "    with torch.set_grad_enabled(False):\n",
    "        pred = model(img.unsqueeze(0))['out'][0][0]\n",
    "\n",
    "        # Treshold the mask to keep pixels which represent positives.\n",
    "        mask = (pred.cpu().numpy() > thresh).astype(np.uint8) * 255\n",
    "\n",
    "        # Reformat the mask to its original size.\n",
    "        mask = cv.resize(mask, orig_shape, None, None, cv.INTER_NEAREST)\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "img = imread(img_fp)\n",
    "pred = predict_mask(model, img)\n",
    "\n",
    "sf = 40 / .25\n",
    "\n",
    "# Extract contours.\n",
    "contours = cv.findContours(pred, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "# Smoothe the contours\n",
    "smoothed_contours = []\n",
    "\n",
    "for contour in contours:\n",
    "    smoothed_contours.append(cv.approxPolyDP(contour, 1, True))\n",
    "\n",
    "# Convert the list of contours to points in DSA format.\n",
    "tissue_points = contours_to_points(smoothed_contours)\n",
    "\n",
    "# Convert each contour into a list dictionary to pass as an annotation \n",
    "# DSA element.\n",
    "tissue_els = []\n",
    "\n",
    "for pt in tissue_points:\n",
    "    # Skip a point with too few points*\n",
    "    # * DSA appears to prevent annotations of three points only.\n",
    "    if len(pt) < 4:\n",
    "        continue\n",
    "        \n",
    "    # Scale the points\n",
    "    pt = np.array(pt) * sf\n",
    "    \n",
    "    tissue_els.append({\n",
    "        'group': 'test',\n",
    "        'type': 'polyline',\n",
    "        'lineColor': 'rgb(0,179,60)',\n",
    "        'lineWidth': 4.0,\n",
    "        'closed': True,\n",
    "        'points': pt.tolist(),\n",
    "        'label': {'value': 'test'},\n",
    "    })\n",
    "\n",
    "# # Push as annotations.\n",
    "# _ = gc.post(\n",
    "#     f\"/annotation?itemId={item['_id']}\", \n",
    "#     json={\n",
    "#         'name': doc_name, \n",
    "#         'description': 'Extracted from low res binary masks.', \n",
    "#         'elements': tissue_els})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c777adc-efb3-4657-809b-9f6b6b8d4b18",
   "metadata": {},
   "source": [
    "## Better Gray Scale Datasets.\n",
    "Create dataset at two sizes - 512 & 1280. Make the images be grayscale instead of RGB and instead of changing the aspect ratio to be square, use padding to avoid changing the original ratio of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee3020f-f98e-41b0-a79a-31dbd5c6e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from pandas import read_csv, DataFrame\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from os.path import join, basename, splitext\n",
    "\n",
    "from neurotk import imread, imwrite\n",
    "from neurotk.utils import create_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c985ff92-90de-450c-aedc-f22de350d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths and directories.\n",
    "save_dir = '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/datasets/' + \\\n",
    "           'tissue-dataset'\n",
    "img_dir = join(save_dir, 'images')\n",
    "mask_dir = join(save_dir, 'labels')\n",
    "create_dirs([img_dir, mask_dir])\n",
    "\n",
    "# Params\n",
    "size = 512\n",
    "grayscale = False  # False for RGB\n",
    "pad = (255, 255, 255)  # value to pad image with\n",
    "blur_kernel = (15, 15)  # size of kernel to blur image with\n",
    "src_fp = '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/' + \\\n",
    "         'tissue-dataset.csv'  # filepath to thumbnail / mask metadata\n",
    "         \n",
    "         \n",
    "def reshape_with_pad(img, size, pad = (255, 255, 255)):\n",
    "    \"\"\"Reshape an image into a square aspect ratio without changing the original\n",
    "    image aspect ratio - i.e. use padding.\n",
    "    \n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    if w > h:\n",
    "        img = cv.copyMakeBorder(img, 0, w-h, 0, 0, cv.BORDER_CONSTANT, None, \n",
    "                                pad)\n",
    "    else:\n",
    "        img = cv.copyMakeBorder(img, 0, 0, 0, h-w, cv.BORDER_CONSTANT, None, \n",
    "                                pad)\n",
    "\n",
    "    # Reshape the image.\n",
    "    img = cv.resize(img, (size, size), None, None, cv.INTER_NEAREST)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ea8da89-f42e-4f39-b6de-435e8ab2f17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098593254ad14b649b254753a6b294cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>label</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fp  \\\n",
       "0  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   \n",
       "1  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   \n",
       "2  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   \n",
       "3  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   \n",
       "4  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   \n",
       "\n",
       "                                               label  size  \n",
       "0  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   512  \n",
       "1  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   512  \n",
       "2  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   512  \n",
       "3  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   512  \n",
       "4  /jcDataStore/Data/NeuroTK-Dash/ml-tissue-detec...   512  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Track information about each image.\n",
    "img_metadata = []\n",
    "\n",
    "df = read_csv(src_fp)\n",
    "\n",
    "for _, r in tqdm(df.iterrows(), total=len(df)):\n",
    "    img = reshape_with_pad(imread(r.fp, grayscale=grayscale), size, pad=pad)\n",
    "    mask = reshape_with_pad(imread(r.label, grayscale=grayscale), size, pad=0)\n",
    "\n",
    "    # Blur mask to get edges smoother.\n",
    "    mask = cv.GaussianBlur(mask, (15,15), 0, 0)\n",
    "    mask = (mask > 0).astype(np.uint8) * 255\n",
    "\n",
    "    fn = f'{splitext(basename(r.fp))[0]}.png'\n",
    "    img_fp = join(img_dir, fn)\n",
    "    mask_fp = join(mask_dir, fn)\n",
    "\n",
    "    # Save image and mask\n",
    "    imwrite(img_fp, img)\n",
    "    imwrite(mask_fp, mask, grayscale=grayscale)\n",
    "\n",
    "    img_metadata.append([img_fp, mask_fp, size])\n",
    "\n",
    "# Save the metadata.\n",
    "img_metadata = DataFrame(img_metadata, columns=['fp', 'label', 'size'])\n",
    "img_metadata.to_csv(join(save_dir, 'dataset.csv'), index=False)\n",
    "img_metadata.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tissue-detection]",
   "language": "python",
   "name": "conda-env-tissue-detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
