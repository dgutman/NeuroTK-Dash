{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devel\n",
    "Developing code, snippets, debugging, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model sizes\n",
    "Report the size of different model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model = deeplabv3_model(input_mode='grayscale')\n",
    "dl_model.eval()\n",
    " \n",
    "print(f'Number of parameters in DeepLabV3 model: {count_parameters(dl_model)}.')\n",
    "\n",
    "un_model = UNet(n_channels=1, n_classes=1)\n",
    "un_model.eval()\n",
    "\n",
    "print(f'Number of parameters in UNet model: {count_parameters(un_model)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on an image with each model.\n",
    "img = Image.open(\n",
    "    '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/images/'\n",
    "    '1023340_1280.png'\n",
    ").convert('L')\n",
    "\n",
    "img = Resize((256, 256))(img)\n",
    "img = ToTensor()(img)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "# Predict using deeplabV3 model.\n",
    "dl_out = dl_model(img)['out']\n",
    "\n",
    "print(\n",
    "    f'Output of deeplab model is of size: {dl_out.shape}, min of '\n",
    "    f'{dl_out.min():.3f}, and max of {dl_out.max():.3f}'\n",
    ")\n",
    "\n",
    "un_out = un_model(img)\n",
    "\n",
    "print(\n",
    "    f'Output of UNet model is of size: {un_out.shape}, min of '\n",
    "    f'{un_out.min():.3f}, and max of {un_out.max():.3f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Code\n",
    "When a model is trained we want some helper functions that can be used to get\n",
    "a report of the model performance on a dataset or set of images.\n",
    "\n",
    "To do:\n",
    "* Given a dataset - CSV file, calculate a metric, e.g. DICE, for predictions on all those images\n",
    "* To the function above, add an optional parameter for saving prediction masks for all those images\n",
    "* Also just need a function that predicts the masks without calculating the metric, such as for dataets that have no ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a trained model.\n",
    "import torch\n",
    "\n",
    "model = deeplabv3_model(input_mode='rgb')\n",
    "\n",
    "model.load_state_dict(torch.load(\n",
    "    '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/models/'\n",
    "    'tissue-model-ml/best.pt'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6d30b636e1469d9bd507d1414f22ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Union\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from neurotk import imwrite\n",
    "from neurotk.utils import create_dirs, get_filename\n",
    "from neurotk.torch.datasets import BinarySSDataset\n",
    "from neurotk.torchvision.semantic_segmentation_transforms import (\n",
    "    Compose, ToTensor, Resize\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module, data: Union[str, DataFrame], save_dir: str = '.',\n",
    "    img_size: int = 512, input_mode: str = 'rgb', batch_size: int = 6,\n",
    "    device: str = 'cpu', thr: float = 0.7, save_mask: bool = False\n",
    "):\n",
    "    \"\"\"Evaluate a model on a dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: Model.\n",
    "        data: Filepath to csv or the dataframe with the images to evaluate. The\n",
    "            fp column contains the image filepath and label column contains the\n",
    "            label mask images (optional).\n",
    "        save_dir: Directory to save images to.\n",
    "        img_size: Image size to use when predicting, images will be resized.\n",
    "        input_mode: Use 'rgb' or 'grayscale' images.\n",
    "        batch_size: Size of batches to use when predicting.\n",
    "        device: Either cpu, cuda, or a specific cuda index (e.g. 0, 1, 2, etc.).\n",
    "        thr: Threshold value for predictions for binary conversion.\n",
    "        save_mask: Save binary prediction masks.\n",
    "    \n",
    "    \"\"\"\n",
    "    assert input_mode in ('grayscale', 'rgb')\n",
    "\n",
    "    if device in ('cpu', 'cuda'):\n",
    "        device = torch.device(device)\n",
    "    else:\n",
    "        device = torch.device(f'cuda:{device}')\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    transforms = Compose([ToTensor(), Resize((img_size, img_size))])\n",
    "\n",
    "    if isinstance(data, str):\n",
    "        data =  pd.read_csv(data)\n",
    "\n",
    "    # Create dataloader.\n",
    "    dataloader = DataLoader(\n",
    "        BinarySSDataset(data, transforms=transforms), batch_size=batch_size, \n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Create subdirectories to same images.\n",
    "    pred_dir = join(save_dir, 'predictions/masks')\n",
    "    create_dirs([pred_dir])\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        image, mask = batch['image'].to(device), batch['mask'].to(device)\n",
    "        info = batch['info']\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = model(image)['out']\n",
    "\n",
    "            # Threshold the prediction.\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "\n",
    "        pred = (pred > thr).astype(np.uint8) * 255\n",
    "\n",
    "        if save_mask:\n",
    "            # Loop through each image and save it.\n",
    "            for i in range(pred.shape[0]):\n",
    "                mask = pred[i][0]\n",
    "\n",
    "                # Get file name.\n",
    "                fn = get_filename(info['fp'][i])\n",
    "\n",
    "                imwrite(join(pred_dir, fn + '.png'), mask)\n",
    "\n",
    "    return 'Done'\n",
    "\n",
    "    \n",
    "temp = evaluate(\n",
    "    model, \n",
    "    '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/dataset-512.csv',\n",
    "    save_dir='temp',\n",
    "    device='0'\n",
    ")\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLabV3: Best Hyperparams from WandDB Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model based on loss is mild-violet-65.\n",
      "   loss=0.002063   dice=0.961\n",
      "\n",
      "Best model based on Dice is generous-sky-58.\n",
      "   loss=0.003978   dice=0.975\n",
      "\n",
      "Choosing the model base on loss, because the Dice metric is based on\n",
      "a single threshold while the loss does not use an arbitrary threshold.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name                                mild-violet-65\n",
       "State                                     finished\n",
       "Notes                                            -\n",
       "User                                      dagutman\n",
       "Tags                                           NaN\n",
       "Created                   2023-09-15T22:20:13.000Z\n",
       "Runtime                                       2739\n",
       "Sweep                                          NaN\n",
       "batch_size                                       8\n",
       "epochs                                          30\n",
       "lr                                        0.000228\n",
       "epoch_dice coefficient                    0.960836\n",
       "epoch_loss                                0.002063\n",
       "Name: 15, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('wandb_export_2023-09-18T10_43_58.816-04_00.csv')\n",
    "\n",
    "# Report the best loss and the best dice metric*\n",
    "# * checking if these are the same model\n",
    "r1 = df.sort_values('epoch_loss').iloc[0]\n",
    "print(f'Best model based on loss is {r1.Name}.')\n",
    "print(f\"   loss={r1.epoch_loss:.6f}   dice={r1['epoch_dice coefficient']:.3f}\")\n",
    "\n",
    "r2 = df.sort_values('epoch_dice coefficient', ascending=False).iloc[0]\n",
    "print(f'\\nBest model based on Dice is {r2.Name}.')\n",
    "print(f\"   loss={r2.epoch_loss:.6f}   dice={r2['epoch_dice coefficient']:.3f}\")\n",
    "\n",
    "print('\\nChoosing the model base on loss, because the Dice metric is based on\\n'\n",
    "      'a single threshold while the loss does not use an arbitrary threshold.')\n",
    "display(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Models Evaluation\n",
    "Use trained semantic segmentation models, mainly DeepLabV3, to validate on datasets.\n",
    "\n",
    "Report: metrics for the dataset, prediction masks, and overlays for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from neurotk.torch.models import deeplabv3_model\n",
    "from neurotk.torch.validation import validate_semantic_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:17<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU: 0.9638580637595507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a model with pre-trained weights.\n",
    "model = deeplabv3_model(classes=1, input_mode='rgb')\n",
    "\n",
    "model_fp = '/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/models/' + \\\n",
    "           'wandb-deeplab-tissue-model/best.pt'\n",
    "           \n",
    "data = pd.read_csv('/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/' + \\\n",
    "                   'datasets/tissue-dataset/dataset.csv')\n",
    "data = train_test_split(data, test_size=0.2, random_state=64)[1]\n",
    "           \n",
    "model.load_state_dict(torch.load(model_fp))\n",
    "_ = model.eval()\n",
    "\n",
    "iou = validate_semantic_segmentation(\n",
    "    model, data, device='cuda', sigmoid=False, thr=0.7,\n",
    "    save_dir='/jcDataStore/Data/NeuroTK-Dash/ml-tissue-detection/'\n",
    "             'models/wandb-deeplab-tissue-model/',\n",
    "    save_figs=True\n",
    ")\n",
    "\n",
    "print(f'IoU: {iou}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissue-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
