{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devel\n",
    "\n",
    "Developing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('/jcDataStore/Projects/NeuroTK-Dash')\n",
    "\n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "from typing import Optional, Tuple\n",
    "import large_image\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "from geopandas import GeoDataFrame, GeoSeries\n",
    "\n",
    "from neurotk import login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO Inference for DAPI Nuclear Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params that will be CLIs.\n",
    "args = {\n",
    "    'in_file': '/jcDataStore/Data/NeuroTK-Dash/example-images/'\n",
    "               '9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI.lif',\n",
    "    'frame': 2,\n",
    "    'device': '0', \n",
    "    'max_det': 1000, \n",
    "    'conf_thr': 0.5,\n",
    "    'iou_thr': 0.4,\n",
    "    'fill': [0, 0, 0],\n",
    "    'contained_thr': 0.6,\n",
    "}\n",
    "\n",
    "# Conver the dictionary to an object with attributes.\n",
    "class ArgumentParser():\n",
    "    def __init__(self, my_dict):\n",
    "        for k, v in my_dict.items():\n",
    "            setattr(self, k, v)\n",
    "            \n",
    "    \n",
    "args = ArgumentParser(args)\n",
    "\n",
    "# Load model.\n",
    "model = YOLO(\n",
    "    '/jcDataStore/Data/NeuroTK-Dash/models/nuclei-detection/version1/'\n",
    "    'weights/best.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Girder Client\n",
    "gc = login('http://glasslab.neurology.emory.edu:8080/api/v1', \n",
    "           username='jvizcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(df, thr):\n",
    "    \"\"\"Apply non-max suppression (nms) on a set of prediction boxes. \n",
    "    Source: https://github.com/rbgirshick/fast-rcnn/blob/master/lib/utils/nms.py\n",
    "    \n",
    "    INPUTS\n",
    "    ------\n",
    "    df : dataframe\n",
    "        data for each box, must contain the x1, y1, x2, y2, conf columns with point 1 being top left of the box and point 2 and bottom\n",
    "        right of box\n",
    "    thr : float\n",
    "        IoU threshold used for nms\n",
    "    \n",
    "    RETURN\n",
    "    ------\n",
    "    df : dataframe\n",
    "        remaining boxes\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df.reset_index(drop=True)  # indices must be reset\n",
    "    dets = df[['x1', 'y1', 'x2', 'y2', 'conf']].to_numpy()\n",
    "    x1 = dets[:, 0]\n",
    "    y1 = dets[:, 1]\n",
    "    x2 = dets[:, 2]\n",
    "    y2 = dets[:, 3]\n",
    "    scores = dets[:, 4]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= thr)[0]\n",
    "        order = order[inds + 1]\n",
    "        \n",
    "    return df.loc[keep]\n",
    "\n",
    "\n",
    "def remove_contained_boxes(df, thr):\n",
    "    \"\"\"Remove boxes contained in other boxes, or mostly contained. \n",
    "    \n",
    "    INPUTS\n",
    "    ------\n",
    "    df : geodataframe\n",
    "        info about each box\n",
    "    thr : float\n",
    "        the threshold of the box that must be contained by fraction of area to be remove\n",
    "       \n",
    "    RETURNS\n",
    "    -------\n",
    "    df : geodataframe\n",
    "        the boxes that are left\n",
    "    \n",
    "    \"\"\"\n",
    "    rm_idx = []\n",
    "    \n",
    "    gseries = GeoSeries(df.geometry.tolist(), index=df.index.tolist())  # convert to a geoseries\n",
    "    \n",
    "    for i, geo in gseries.items():\n",
    "        # don't check boxes that have already been removed\n",
    "        if i not in rm_idx:\n",
    "            r = df.loc[i]\n",
    "            \n",
    "            # remove boxes that don't overlap\n",
    "            overlapping = df[\n",
    "                (~df.index.isin(rm_idx + [i])) & ~((r.y2 < df.y1) | (r.y1 > df.y2) | (r.x2 < df.x1) | (r.x1 > df.x2))\n",
    "            ]\n",
    "            \n",
    "            perc_overlap = overlapping.intersection(geo).area / overlapping.area  # percent of object inside the current geo\n",
    "            \n",
    "            # filter by the threshold\n",
    "            overlapping = overlapping[perc_overlap > thr]\n",
    "            \n",
    "            rm_idx.extend(overlapping.index.tolist())\n",
    "            \n",
    "    return df.drop(index=rm_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on tiles for 2 batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35631c630e47421d85e8d49af061299d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging overlapping boxes from a starting 1620 boxes...\n",
      "    894 final predicted boxes.\n"
     ]
    }
   ],
   "source": [
    "# WSI inference function.\n",
    "def wsi_inference(\n",
    "    fp: str, model: nn.Module, mask: Optional[np.ndarray] = None, \n",
    "    frame: Optional[int] = None, mag: Optional[float] = None,\n",
    "    tile_size: int = 1280, stride: int = 960, batch_size: int = 10,\n",
    "    device: str = 'cpu', max_det: int = 1000, iou_thr: float = 0.6, \n",
    "    conf_thr: float = 0.5, fill: Tuple[int, int, int] = (255, 255, 255),\n",
    "    contained_thr: float = 0.8 \n",
    "):\n",
    "    \"\"\"Inference a YOLO model on a large image by tiling it into smaller \n",
    "    overlapping regions and then merging predictions.\n",
    "    \n",
    "    Args:\n",
    "        fp (str): Filepath to image, must be openable by large_image.\n",
    "        model (torch.nn.Module): Model used to predict labels.\n",
    "        mask (numpy.ndarray): Optional low resolution mask used to narrow\n",
    "            down the regions to analyze in the image. If None then the entire\n",
    "            image is analyzed.\n",
    "        frame (int): Optional frame of multiplex image to analyze.\n",
    "        mag (int): Optional magnification to analyze images at.\n",
    "        tile_size (int): Tile size.\n",
    "        stride (int): Stride size during tiling.\n",
    "        batch_size (int): Number of images to predict in bulk.\n",
    "        device (str): Options are 'cuda', 'cpu', or the ids of GPU devices (i.e.\n",
    "            0,1,2,etc.).\n",
    "        max_det (int): Maximum number of detection per tile.\n",
    "        iou (float): IoU threshold when running NMS during prediction in a tile.\n",
    "        conf (float): Confidence threshold, predictions below this threshold are\n",
    "            discarded.\n",
    "        fill (Tuple[int, int, int]): RGB color to fill tiles regions to not be\n",
    "            analyzed.\n",
    "        \n",
    "            \n",
    "    \"\"\"\n",
    "    # Get image tilesource, currently throwing warnings for these images.\n",
    "    ts = large_image.getTileSource(fp)\n",
    "    \n",
    "    ts_metadata = ts.getMetadata()\n",
    "        \n",
    "    if mag is not None and ts_metadata['magnification'] is not None:\n",
    "        # Mult. factor: Desired magnification -> Scan magnifiction\n",
    "        fr_to_mag = ts_metadata['magnification'] / mag\n",
    "        fr_tile_size = int(tile_size * fr_to_mag)\n",
    "        fr_stride = int(stride * fr_to_mag)\n",
    "    else:\n",
    "        fr_tile_size, fr_stride = tile_size, stride\n",
    "    \n",
    "    # Calculate the x, y coordinates of the top left of each tile.\n",
    "    xys = []\n",
    "    \n",
    "    for y in range(0, ts_metadata['sizeY'], fr_stride):\n",
    "        for x in range(0, ts_metadata['sizeX'], fr_stride):\n",
    "            if mask is None:\n",
    "                xys.append((x, y))\n",
    "            else:\n",
    "                print(\"Mask support not currently available, defaulting to \"\n",
    "                      \"include all tiles.\")\n",
    "                # Add logic here checking if this tile is sufficiently enough\n",
    "                # to include for predicting.\n",
    "    \n",
    "    pred_df = []  # track all predictions in dataframe\n",
    "    \n",
    "    # Predict on tiles in batches.\n",
    "    idx = list(range(0, len(xys), batch_size))\n",
    "    \n",
    "    print(f'Predicting on tiles for {len(idx)} batches.')\n",
    "    for i in tqdm(idx):\n",
    "        imgs = []\n",
    "        \n",
    "        batch_xys = xys[i:i+batch_size]\n",
    "        \n",
    "        for xy in batch_xys:\n",
    "            x, y = xy\n",
    "            \n",
    "            img = ts.getRegion(\n",
    "                region={\n",
    "                    'left': x, 'top': y, \n",
    "                    'right':x + fr_tile_size, 'bottom': y + fr_tile_size\n",
    "                },\n",
    "                format=large_image.constants.TILE_FORMAT_NUMPY,\n",
    "                scale={'magnification': mag},\n",
    "                frame=frame\n",
    "            )[0]\n",
    "            \n",
    "            img_shape = img.shape\n",
    "                        \n",
    "            if img_shape[2] == 1:\n",
    "                img = cv.cvtColor(img[:, :, 0], cv.COLOR_GRAY2RGB)\n",
    "                                                \n",
    "            # Pad the image if needed\n",
    "            if img_shape[:2] != (tile_size, tile_size):\n",
    "                img = cv.copyMakeBorder(\n",
    "                    img, 0, tile_size - img_shape[0], 0, \n",
    "                    tile_size - img_shape[1], cv.BORDER_CONSTANT, None, fill\n",
    "                )     \n",
    "                \n",
    "            imgs.append(img)\n",
    "            \n",
    "        batch_out = model.predict(\n",
    "            imgs,\n",
    "            device=device,\n",
    "            max_det=max_det,\n",
    "            iou=iou_thr,\n",
    "            conf=conf_thr,\n",
    "            imgsz=tile_size,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        for xy, out in zip(batch_xys, batch_out):\n",
    "            x, y = xy\n",
    "            \n",
    "            boxes = out.boxes\n",
    "            \n",
    "            for label, box, cf in zip(boxes.cls, boxes.xyxy, boxes.conf):\n",
    "                box = box.cpu().detach().numpy()\n",
    "                label = label.cpu().detach().numpy()\n",
    "                cf = cf.cpu().detach().numpy()\n",
    "                \n",
    "                x1, y1, x2, y2 = box[0] + x, box[1] + y, box[2] + x, box[3] + y\n",
    "                        \n",
    "                pred_df.append([\n",
    "                    int(label), x1, y1, x2, y2, cf,\n",
    "                    Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)]), \n",
    "                    (x2-x1)*(y2-y1)\n",
    "                ])\n",
    "           \n",
    "    # Compile boxes into dataframe.     \n",
    "    pred_df = GeoDataFrame(\n",
    "        pred_df, \n",
    "        columns=['label', 'x1', 'y1', 'x2', 'y2', 'conf', 'geometry', \n",
    "                 'box_area']\n",
    "    )\n",
    "    \n",
    "    print(f\"Merging overlapping boxes from a starting {len(pred_df)} boxes...\")\n",
    "    pred_df = non_max_suppression(pred_df, iou_thr)\n",
    "    pred_df = remove_contained_boxes(pred_df, contained_thr)\n",
    "    print(f'    {len(pred_df)} final predicted boxes.')\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "    \n",
    "pred_df = wsi_inference(\n",
    "    args.in_file, \n",
    "    model,\n",
    "    frame=args.frame,\n",
    "    device=args.device,\n",
    "    max_det=args.max_det,\n",
    "    iou_thr=args.iou_thr,\n",
    "    conf_thr=args.conf_thr,\n",
    "    fill=args.fill,\n",
    "    contained_thr=args.contained_thr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push results to DSA as annotations.\n",
    "elements = []\n",
    "\n",
    "for _, r in pred_df.iterrows():\n",
    "    tile_w, tile_h = r.x2 - r.x1, r.y2 - r.y1\n",
    "    tile_center = [(r.x2 + r.x1) / 2, (r.y2 + r.y1) / 2, 0]\n",
    "    label = int(r.label)\n",
    "\n",
    "    elements.append({\n",
    "        'lineColor': 'rgb(0,255,0)',\n",
    "        'lineWidth': 2,\n",
    "        'rotation': 0,\n",
    "        'type': 'rectangle',\n",
    "        'center': tile_center,\n",
    "        'width': tile_w,\n",
    "        'height': tile_h,\n",
    "        'label': {'value': 'nucleus'},\n",
    "        'group': 'nucleus'\n",
    "    })\n",
    "    \n",
    "_ = gc.post(\n",
    "    f'/annotation?itemId=65088a9b9a8ab9ec771ba6b6', \n",
    "    json={\n",
    "        'name': f'yolo-inference-test-smaller-thresholds', \n",
    "        'description': '', \n",
    "        'elements': elements\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurotk-cli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
